// Remote write endpoint for metrics
prometheus.remote_write "metrics_service" {
    endpoint {
        url = "https://prometheus-prod-52-prod-ap-southeast-2.grafana.net/api/prom/push"
        basic_auth {
            username = env("GRAFANA_CLOUD_PROM_USERNAME")
            password = env("GRAFANA_CLOUD_PROM_PASSWORD")
        }
    }
}

// Loki endpoint for logs
loki.write "grafana_cloud_loki" {
    endpoint {
        url = "https://logs-prod-032.grafana.net/loki/api/v1/push"
        basic_auth {
            username = env("GRAFANA_CLOUD_LOKI_USERNAME")
            password = env("GRAFANA_CLOUD_LOKI_PASSWORD")
        }
    }
}



otelcol.exporter.otlp "grafana_cloud_tempo" {
  client {
    endpoint = env("GRAFANA_CLOUD_TEMPO_ENDPOINT")
    auth     = otelcol.auth.basic.grafana_cloud.handler
    tls {
      insecure = false
    }
  }
}

otelcol.auth.basic "grafana_cloud" {
  username = env("GRAFANA_CLOUD_TEMPO_USERNAME")
  password = env("GRAFANA_CLOUD_TEMPO_PASSWORD")
}


// =========================================================================
// NODE EXPORTER INTEGRATION (using Alloy's built-in prometheus.exporter.unix)
// =========================================================================

prometheus.exporter.unix "integrations_node_exporter" {

  rootfs_path = "/host"  
  disable_collectors = ["ipvs", "btrfs", "infiniband", "xfs", "zfs"]

  filesystem {
    fs_types_exclude   = "^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|tmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)$"
    mount_points_exclude = "^/(dev|proc|run/credentials/.+|sys|var/lib/docker/.+)($|/)"
    mount_timeout      = "5s"
  }

  netclass {
    ignored_devices = "^(veth.*|cali.*|[a-f0-9]{15})$"
  }

  netdev {
    device_exclude = "^(veth.*|cali.*|[a-f0-9]{15})$"
  }
}

discovery.relabel "metrics_node_exporter_targets" {
  // Targets are generated by the built-in unix exporter
  targets = prometheus.exporter.unix.integrations_node_exporter.targets

  rule {
    target_label = "instance"
    replacement  = constants.hostname // Use constants.hostname for instance
  }

  rule {
    target_label = "job"
    replacement = "integrations/node_exporter" // Match desired job name
  }
}

prometheus.scrape "metrics_node_exporter" {
  targets     = discovery.relabel.metrics_node_exporter_targets.output
  forward_to  = [prometheus.relabel.metrics_node_exporter.receiver]
  job_name    = "integrations/node_exporter" // Set job_name here directly
  scrape_interval = "15s"
  // metrics_path is not explicitly needed here as prometheus.exporter.unix handles it internally
}

prometheus.relabel "metrics_node_exporter" {
  forward_to = [prometheus.remote_write.metrics_service.receiver]

  // Drop scrape collector metrics (they're not useful)
  rule {
    source_labels = ["__name__"]
    regex         = "node_scrape_collector_.+"
    action        = "drop"
  }

  // Add environment label (if not already added by default in the previous chain)
  rule {
    target_label = "environment"
    replacement  = "production"
  }
}


// =========================================================================
// POSTGRES EXPORTER INTEGRATION (using Alloy's built-in exporter)
// =========================================================================

prometheus.exporter.postgres "postgres_metrics_exporter" {
    data_source_names = [env("POSTGRES_DSN")]
}

discovery.relabel "metrics_postgres_targets" {
    targets = prometheus.exporter.postgres.postgres_metrics_exporter.targets

    rule {
        target_label = "instance"
        replacement  = constants.hostname // Use constants.hostname for instance
    }
    rule {
        target_label = "job"
        replacement  = "integrations/postgres_exporter" // Match desired job name
    }
}

prometheus.scrape "postgres_metrics" {
    targets     = discovery.relabel.metrics_postgres_targets.output
    forward_to  = [prometheus.relabel.metrics_postgres.receiver]
    job_name    = "integrations/postgres_exporter" // Set job_name here directly
    scrape_interval = "30s"
    metrics_path = "/metrics"
}

prometheus.relabel "metrics_postgres" {
    forward_to = [prometheus.remote_write.metrics_service.receiver]

    // Keep only the specified list of metrics
    rule {
      source_labels = ["__name__"]
      regex         = "pg_settings_max_connections|pg_settings_superuser_reserved_connections|pg_stat_activity_count|pg_stat_activity_max_tx_duration|pg_stat_bgwriter_buffers_alloc_total|pg_stat_bgwriter_buffers_backend_fsync_total|pg_stat_bgwriter_buffers_backend_total|pg_stat_bgwriter_buffers_checkpoint_total|pg_stat_bgwriter_buffers_clean_total|pg_stat_database_blks_hit|pg_stat_database_blks_read|pg_stat_database_conflicts|pg_stat_database_deadlocks|pg_stat_database_numbackends|pg_stat_database_tup_deleted|pg_stat_database_tup_fetched|pg_stat_database_tup_inserted|pg_stat_database_tup_returned|pg_stat_database_tup_updated|pg_stat_database_xact_commit|pg_stat_database_xact_rollback|pg_up|up"
      action        = "keep"
    }

    // Add environment label
    rule {
        target_label = "environment"
        replacement  = "production"
    }
}

// =========================================================================
// POSTGRES LOGS INTEGRATION (from local file)
// =========================================================================

local.file_match "logs_postgres_files" {
    path_targets = [{
        __address__ = "localhost",
        __path__    = "/var/log/postgresql/postgres.log",
        instance    = constants.hostname, // Identifies the host where logs are collected
        job         = "integrations/postgres_exporter", // Match desired job name for logs
        environment = "production",
    }]
}

loki.source.file "postgres_logs" {
    targets    = local.file_match.logs_postgres_files.targets
    forward_to = [loki.relabel.postgres_logs.receiver]
}

loki.relabel "postgres_logs" {
    forward_to = [loki.write.grafana_cloud_loki.receiver]
}


// =========================================================================
// GO APPLICATIONS INTEGRATION
// =========================================================================

discovery.relabel "metrics_go_applications_targets" {
  targets = [
    {__address__ = "goapp1:8080"},
    {__address__ = "goapp2:8080"},
    {__address__ = "goapp3:8080"},
  ]
}

prometheus.scrape "metrics_go_applications" {
  targets     = discovery.relabel.metrics_go_applications_targets.output
  forward_to  = [prometheus.relabel.metrics_go_applications.receiver]
  job_name    = "go_application" // Specific job for Go app metrics
  scrape_interval = "15s"
  metrics_path = "/metrics"
}

prometheus.relabel "metrics_go_applications" {
  forward_to = [prometheus.remote_write.metrics_service.receiver]

  // Add application type label
  rule {
    target_label = "app_type"
    replacement  = "go_service"
  }

  // Add environment label
  rule {
    target_label = "environment"
    replacement  = "production"
  }
}


// =========================================================================
// DOCKER CONTAINER LOGS
// =========================================================================

discovery.docker "containers" {
  host = "unix:///var/run/docker.sock"
}

discovery.relabel "loki_docker_containers_targets" {
  targets = discovery.docker.containers.targets

  // Only collect logs from containers with specific labels
  rule {
    source_labels = ["__meta_docker_container_label_coolify_managed"]
    regex = "true"
    action = "keep"
  }

  rule {
    source_labels = ["__meta_docker_container_name"]
    target_label = "container"
  }

  rule {
    source_labels = ["__meta_docker_container_label_coolify_applicationId"]
    target_label = "application_id"
  }

  // The job for Loki logs from Docker containers
  rule {
    target_label = "job"
    replacement = "docker_container_logs" // Specific job name for logs
  }
}

loki.source.docker "containers" {
  host            = "unix:///var/run/docker.sock"
  targets         = discovery.relabel.loki_docker_containers_targets.output
  forward_to      = [loki.relabel.loki_docker_containers.receiver]
  relabel_rules   = discovery.relabel.loki_docker_containers_targets.rules
}

loki.relabel "loki_docker_containers" {
  forward_to = [loki.write.grafana_cloud_loki.receiver]

  rule {
    target_label = "environment"
    replacement = "production"
  }
}

// =========================================================================
// JOURNALD LOGS INTEGRATION (via custom module)
// =========================================================================

loki.relabel "integrations_node_exporter_journal_logs" {
  forward_to = [loki.write.grafana_cloud_loki.receiver]
  rule {
    target_label = "job"
    replacement  = "integrations/node_exporter" // Match desired job name for journal logs
  }
  rule {
    target_label = "instance"
    replacement  = constants.hostname // Set instance for journal logs
  }
  rule {
    target_label = "environment" // Add environment label
    replacement  = "production"
  }
}

// Define the journal_module. This should typically be declared once.
declare "journal_module" {
  argument "forward_to" {
      optional = false
  }

  loki.source.journal "default"  {
      max_age       = "12h0m0s"
      forward_to    = [loki.process.default.receiver]
      relabel_rules = loki.relabel.default.rules
  }

  loki.relabel "default" {
      rule {
          source_labels = ["__journal__systemd_unit"]
          target_label  = "unit"
      }
      rule {
          source_labels = ["__journal__boot_id"]
          target_label  = "boot_id"
      }
      rule {
          source_labels = ["__journal__transport"]
          target_label  = "transport"
      }
      rule {
          source_labels = ["__journal_priority_keyword"]
          target_label  = "level"
      }
      // This forward_to should send to loki.process.default.receiver, not an empty list
      forward_to    = [] // This is actually for the process block
  }
  loki.process "default" {
      forward_to    = argument.forward_to.value
  }
}

// Instantiate the journal_module
journal_module "node_exporter_journal" {
  forward_to = [loki.relabel.integrations_node_exporter_journal_logs.receiver]
}


// =========================================================================
// OPEN TELEMETRY TRACES INTEGRATION (NEW)
// =========================================================================

// OTLP Receiver: Listens for traces from your Go application


otelcol.exporter.debug "debug_traces" {
  verbosity = "detailed"
}

otelcol.receiver.otlp "default" {
  http {
    endpoint = "0.0.0.0:4318"
  }
  grpc {
    endpoint = "0.0.0.0:4317"
  }
  output {
    traces = [
      otelcol.exporter.otlp.grafana_cloud_tempo.input,
      otelcol.exporter.debug.debug_traces.input,
    ]
  }
}

